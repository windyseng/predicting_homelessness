{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING HOMELESSNESS IN AMERICA\n",
    "\n",
    "## Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUD Annual Homeless Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from: https://www.hudexchange.info/resource/3031/pit-and-hic-data-since-2007/ .\n",
    "I will convert the files into a single dataframe with the COC number, total count, and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK-500</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL-500</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL-501</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL-502</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num  2016\n",
       "0  AK-500  1105\n",
       "1  AK-501   835\n",
       "2  AL-500  1228\n",
       "3  AL-501   623\n",
       "4  AL-502   337"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016 = pd.read_csv('homeless_2016.csv')\n",
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.rename({'2016':'homeless_count'}, axis=1, inplace=True)\n",
    "df_2016['yr'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>homeless_count</th>\n",
       "      <th>yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK-500</td>\n",
       "      <td>1105</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK-501</td>\n",
       "      <td>835</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL-500</td>\n",
       "      <td>1228</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL-501</td>\n",
       "      <td>623</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL-502</td>\n",
       "      <td>337</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num homeless_count    yr\n",
       "0  AK-500           1105  2016\n",
       "1  AK-501            835  2016\n",
       "2  AL-500           1228  2016\n",
       "3  AL-501            623  2016\n",
       "4  AL-502            337  2016"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to format HUD files in order to merge into a single dataframe\n",
    "def import_counts(year, file):\n",
    "    table = pd.read_csv(file)\n",
    "    table['yr'] = year\n",
    "    table.rename({str(year):'homeless_count'}, axis=1, inplace=True)\n",
    "    table.dropna(axis=0, inplace=True)\n",
    "    return table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = import_counts(2015,'homeless_2015.csv')\n",
    "df_2014 = import_counts(2014,'homeless_2014.csv')\n",
    "df_2013 = import_counts(2013,'homeless_2013.csv')\n",
    "df_2012 = import_counts(2012,'homeless_2012.csv')\n",
    "df_2011 = import_counts(2011,'homeless_2011.csv')\n",
    "df_2010 = import_counts(2010,'homeless_2010.csv')\n",
    "df_2009 = import_counts(2009,'homeless_2009.csv')\n",
    "df_2008 = import_counts(2008,'homeless_2008.csv')\n",
    "df_2007 = import_counts(2007,'homeless_2007.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merg = [df_2016, df_2015, df_2014, df_2013, df_2012, df_2011, df_2010, df_2009, df_2008, df_2007]\n",
    "data = pd.concat(merg, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3943, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to a csv file, this is the outcome data to be used in my predictive models\n",
    "#data.to_csv('homeless_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing SSI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded from https://www.ssa.gov/policy/docs/statcomps/ssi_sc/2016/index.html . I will create functions that compile state data by sheet in every annual excel workbook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each workbook will have the same pages\n",
    "#DC not in list, this state is missing from multiple files\n",
    "\n",
    "sheets = ['Table 3 - Alabama',\n",
    "'Table 3 - Alaska',\n",
    "'Table 3 - Arizona',\n",
    "'Table 3 - Arkansas',\n",
    "'Table 3 - California',\n",
    "'Table 3 - Colorado',\n",
    "'Table 3 - Connecticut',\n",
    "'Table 3 - Delaware',\n",
    "'Table 3 - Florida',\n",
    "'Table 3 - Georgia',\n",
    "'Table 3 - Hawaii',\n",
    "'Table 3 - Idaho',\n",
    "'Table 3 - Illinois',\n",
    "'Table 3 - Indiana',\n",
    "'Table 3 - Iowa',\n",
    "'Table 3 - Kansas',\n",
    "'Table 3 - Kentucky',\n",
    "'Table 3 - Louisiana',\n",
    "'Table 3 - Maine',\n",
    "'Table 3 - Maryland',\n",
    "'Table 3 - Massachusetts',\n",
    "'Table 3 - Michigan',\n",
    "'Table 3 - Minnesota',\n",
    "'Table 3 - Mississippi',\n",
    "'Table 3 - Missouri',\n",
    "'Table 3 - Montana',\n",
    "'Table 3 - Nebraska',\n",
    "'Table 3 - Nevada',\n",
    "'Table 3 - New Hampshire',\n",
    "'Table 3 - New Jersey',\n",
    "'Table 3 - New Mexico',\n",
    "'Table 3 - New York',\n",
    "'Table 3 - North Carolina',\n",
    "'Table 3 - North Dakota',\n",
    "'Table 3 - Ohio',\n",
    "'Table 3 - Oklahoma',\n",
    "'Table 3 - Oregon',\n",
    "'Table 3 - Pennsylvania',\n",
    "'Table 3 - Rhode Island',\n",
    "'Table 3 - South Carolina',\n",
    "'Table 3 - South Dakota',\n",
    "'Table 3 - Tennessee',\n",
    "'Table 3 - Texas',\n",
    "'Table 3 - Utah',\n",
    "'Table 3 - Vermont',\n",
    "'Table 3 - Virginia',\n",
    "'Table 3 - Washington',\n",
    "'Table 3 - West Virginia',\n",
    "'Table 3 - Wisconsin',\n",
    "'Table 3 - Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel books from years 2009-2016 are formatted the same, create a list with years in decsending order\n",
    "books = ['ssi_sc16.xlsx', 'ssi_sc15.xlsx', 'ssi_sc14.xlsx','ssi_sc13.xlsx','ssi_sc12.xlsx',\n",
    "         'ssi_sc11.xlsx','ssi_sc10.xlsx','ssi_sc09.xlsx']\n",
    "\n",
    "# excel books from years 2007-2008 are slightly different from the rest\n",
    "books_2 =['ssi_sc08.xlsx', 'ssi_sc07.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull relevant data from excel docs\n",
    "# files for 2007 & 2008 are different, this function cannot be applied to those workbooks\n",
    "\n",
    "def xl_clean(book, sheet):\n",
    "    ssi_df = pd.read_excel(book, sheet_name = sheet) \n",
    "    ssi_df.drop(ssi_df.index[0:4], inplace=True) \n",
    "    ssi_df = ssi_df.reset_index() \n",
    "\n",
    "    # drop the last 8 rows \n",
    "    y = len(ssi_df.index) \n",
    "    x = y - 8\n",
    "    ssi_df.drop(ssi_df.index[x:y], inplace=True)\n",
    "    \n",
    "    #drop columns that are blank or that contain unnecessary information\n",
    "    ssi_df.drop(['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 9','Unnamed: 10'], axis=1, inplace=True)\n",
    "    \n",
    "    #rename columns for clarity\n",
    "    ssi_df.rename({'Unnamed: 3': 'total_ssi', 'Unnamed: 4': 'aged_ssi','Unnamed: 5': 'disbl_ssi',\n",
    "                   'Unnamed: 6': '18_und_ssi','Unnamed: 7': '18_64_ssi',\n",
    "                   'Unnamed: 8': '65_ovr_ssi'}, axis=1, inplace=True)\n",
    "    \n",
    "    #reset the index again and drop the unnecessary columns\n",
    "    ssi_df = ssi_df.reset_index()\n",
    "    ssi_df.drop(['level_0','index'], axis=1, inplace=True)\n",
    "    \n",
    "    #rename the first column in the sheet \n",
    "    ssi_df.rename(columns={list(ssi_df.columns)[0]:'county'}, inplace=True)\n",
    "    \n",
    "    #add a column with the worksheet name\n",
    "    ssi_df['state'] = sheet\n",
    "    return ssi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop function that runs the above function through each page of one book and stores the data in a dictionary \n",
    "def xl_to_df(book, sheets):\n",
    "    d = {}\n",
    "    for i in range(len(sheets)):\n",
    "        d[i] = xl_clean(book, sheets[i])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(sheets))\n",
    "print(len(books)) \n",
    "#the function will run through 50 pages of 8 workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through every workbook running the function that processes each page of the workbook\n",
    "file = {}\n",
    "for i in range(len(books)):\n",
    "    file[i] = xl_to_df(books[i], sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to merge the data from each workbook page into a single dataframe\n",
    "\n",
    "def assemble(file):\n",
    "    \n",
    "    #make lists of 10 dictionaries or less\n",
    "    list_1 = [file[0],file[1],file[2],file[3],file[4],file[5],\n",
    "              file[6],file[7],file[8],file[9],file[10]]\n",
    "    \n",
    "    list_2 = [file[11],file[12],file[13],file[14],file[15],\n",
    "              file[16],file[17],file[18],file[19],file[20]]\n",
    "    \n",
    "    list_3 = [file[21],file[22],file[23],file[24],file[25],\n",
    "              file[26],file[27],file[28],file[29],file[30]]\n",
    "    \n",
    "    list_4 = [file[31],file[32],file[33],file[34],file[35],\n",
    "              file[36],file[37], file[38],file[39],file[40]]\n",
    "    \n",
    "    list_5 = [file[41],file[42],file[43],file[44],file[45],\n",
    "              file[46],file[47],file[48],file[49]]\n",
    "   \n",
    "    #concat the lists into dataframes and reset the index\n",
    "    df_a = pd.concat(list_1, axis=0)\n",
    "    df_a = df_a.reset_index()\n",
    "    df_a.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    df_b = pd.concat(list_2, axis=0)\n",
    "    df_b = df_b.reset_index()\n",
    "    df_b.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    df_c = pd.concat(list_3, axis=0)\n",
    "    df_c = df_c.reset_index()\n",
    "    df_c.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    df_d = pd.concat(list_4, axis=0)\n",
    "    df_d = df_d.reset_index()\n",
    "    df_d.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    df_e = pd.concat(list_5, axis=0)\n",
    "    df_e = df_e.reset_index()\n",
    "    df_e.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    #create a list of the dataframes\n",
    "    frames = [df_a, df_b, df_c, df_d, df_e]\n",
    "    \n",
    "    #concat the dataframes into a single dataframe\n",
    "    df_ssi = pd.concat(frames, axis=0)\n",
    "    \n",
    "    return df_ssi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function on a single dictionary, since the books were listed in descending order the first file will represent 2016 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>total_ssi</th>\n",
       "      <th>aged_ssi</th>\n",
       "      <th>disbl_ssi</th>\n",
       "      <th>18_und_ssi</th>\n",
       "      <th>18_64_ssi</th>\n",
       "      <th>65_ovr_ssi</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>1467</td>\n",
       "      <td>68</td>\n",
       "      <td>1399</td>\n",
       "      <td>236</td>\n",
       "      <td>1027</td>\n",
       "      <td>204</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>3521</td>\n",
       "      <td>193</td>\n",
       "      <td>3328</td>\n",
       "      <td>607</td>\n",
       "      <td>2384</td>\n",
       "      <td>530</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour</td>\n",
       "      <td>1469</td>\n",
       "      <td>104</td>\n",
       "      <td>1365</td>\n",
       "      <td>233</td>\n",
       "      <td>910</td>\n",
       "      <td>326</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb</td>\n",
       "      <td>966</td>\n",
       "      <td>29</td>\n",
       "      <td>937</td>\n",
       "      <td>95</td>\n",
       "      <td>714</td>\n",
       "      <td>157</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount</td>\n",
       "      <td>1282</td>\n",
       "      <td>62</td>\n",
       "      <td>1220</td>\n",
       "      <td>121</td>\n",
       "      <td>945</td>\n",
       "      <td>216</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county total_ssi aged_ssi disbl_ssi 18_und_ssi 18_64_ssi 65_ovr_ssi  \\\n",
       "0  Autauga      1467       68      1399        236      1027        204   \n",
       "1  Baldwin      3521      193      3328        607      2384        530   \n",
       "2  Barbour      1469      104      1365        233       910        326   \n",
       "3     Bibb       966       29       937         95       714        157   \n",
       "4   Blount      1282       62      1220        121       945        216   \n",
       "\n",
       "               state  \n",
       "0  Table 3 - Alabama  \n",
       "1  Table 3 - Alabama  \n",
       "2  Table 3 - Alabama  \n",
       "3  Table 3 - Alabama  \n",
       "4  Table 3 - Alabama  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssi2016 = assemble(file[0])\n",
    "df_ssi2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through the rest of the dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ssi2015 = assemble(file[1])\n",
    "df_ssi2014 = assemble(file[2])\n",
    "df_ssi2013 = assemble(file[3])\n",
    "df_ssi2012 = assemble(file[4])\n",
    "df_ssi2011 = assemble(file[5])\n",
    "df_ssi2010 = assemble(file[6])\n",
    "df_ssi2009 = assemble(file[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new updated function to process the 2007 & 2008 files, dropping different columns\n",
    "\n",
    "def xl_clean_2(book, sheet):\n",
    "    ssi_8 = pd.read_excel(book, sheet_name = sheet) #convert each sheet to dataframe\n",
    "    ssi_8.drop(ssi_8.index[0:4], inplace=True)#drop the first 4 rows which are not useful \n",
    "    ssi_8 = ssi_8.reset_index()\n",
    "   \n",
    "    #drop the last 8 rows \n",
    "    y = len(ssi_8.index) \n",
    "    x = y - 8\n",
    "    ssi_8.drop(ssi_8.index[x:y], inplace=True)\n",
    "\n",
    "    #drop columns that are blank or that contain unnecessary information\n",
    "    ssi_8.drop(['Unnamed: 1','Unnamed: 8', 'Unnamed: 9'], axis=1, inplace=True)\n",
    "\n",
    "    #rename columns for clarity\n",
    "    ssi_8.rename({'Unnamed: 2': 'total_ssi', 'Unnamed: 3': 'aged_ssi',\n",
    "                  'Unnamed: 4': 'disbl_ssi','Unnamed: 5': '18_und_ssi',\n",
    "                  'Unnamed: 6': '18_64_ssi','Unnamed: 7': '65_ovr_ssi'}, axis=1, inplace=True)\n",
    "    \n",
    "    #reset the index again and drop the unnecessary columns\n",
    "    ssi_8 = ssi_8.reset_index()\n",
    "    ssi_8.drop(['level_0','index'], axis=1, inplace=True)\n",
    "    \n",
    "    #rename the first column in the sheet\n",
    "    ssi_8.rename(columns={list(ssi_8.columns)[0]:'county'}, inplace=True)\n",
    "    \n",
    "    #add a column with the worksheet name\n",
    "    ssi_8['state'] = sheet\n",
    "    \n",
    "    return ssi_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop function that runs the above function through each page of one book and stores the data in a dictionary \n",
    "def xl_to_df_2(book, sheets):\n",
    "    d = {}\n",
    "    for i in range(len(sheets)):\n",
    "        d[i] = xl_clean_2(book, sheets[i])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through every workbook running the function that processes each page of the workbook\n",
    "newfile = {}\n",
    "for i in range(len(books_2)):\n",
    "    newfile[i] = xl_to_df_2(books_2[i], sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run function on both dicts\n",
    "df_ssi2008 = assemble(newfile[0])\n",
    "df_ssi2007 = assemble(newfile[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3149, 8)\n",
      "(3149, 8)\n",
      "(3151, 8)\n",
      "(3150, 8)\n",
      "(3150, 8)\n",
      "(3150, 8)\n",
      "(3142, 8)\n",
      "(3164, 8)\n",
      "(3116, 8)\n",
      "(3096, 8)\n"
     ]
    }
   ],
   "source": [
    "#check shape to ensure same number of columns\n",
    "print(df_ssi2016.shape)\n",
    "print(df_ssi2015.shape)\n",
    "print(df_ssi2014.shape)\n",
    "print(df_ssi2013.shape)\n",
    "print(df_ssi2012.shape)\n",
    "print(df_ssi2011.shape)\n",
    "print(df_ssi2010.shape)\n",
    "print(df_ssi2009.shape)\n",
    "print(df_ssi2008.shape)\n",
    "print(df_ssi2007.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>total_ssi</th>\n",
       "      <th>aged_ssi</th>\n",
       "      <th>disbl_ssi</th>\n",
       "      <th>18_und_ssi</th>\n",
       "      <th>18_64_ssi</th>\n",
       "      <th>65_ovr_ssi</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>1352</td>\n",
       "      <td>123</td>\n",
       "      <td>1229</td>\n",
       "      <td>278</td>\n",
       "      <td>836</td>\n",
       "      <td>238</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2770</td>\n",
       "      <td>248</td>\n",
       "      <td>2522</td>\n",
       "      <td>440</td>\n",
       "      <td>1869</td>\n",
       "      <td>461</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour</td>\n",
       "      <td>1720</td>\n",
       "      <td>223</td>\n",
       "      <td>1497</td>\n",
       "      <td>287</td>\n",
       "      <td>955</td>\n",
       "      <td>478</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb</td>\n",
       "      <td>1070</td>\n",
       "      <td>67</td>\n",
       "      <td>1003</td>\n",
       "      <td>174</td>\n",
       "      <td>723</td>\n",
       "      <td>173</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount</td>\n",
       "      <td>1397</td>\n",
       "      <td>158</td>\n",
       "      <td>1239</td>\n",
       "      <td>186</td>\n",
       "      <td>881</td>\n",
       "      <td>330</td>\n",
       "      <td>Table 3 - Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    county total_ssi aged_ssi disbl_ssi 18_und_ssi 18_64_ssi 65_ovr_ssi  \\\n",
       "0  Autauga      1352      123      1229        278       836        238   \n",
       "1  Baldwin      2770      248      2522        440      1869        461   \n",
       "2  Barbour      1720      223      1497        287       955        478   \n",
       "3     Bibb      1070       67      1003        174       723        173   \n",
       "4   Blount      1397      158      1239        186       881        330   \n",
       "\n",
       "               state  \n",
       "0  Table 3 - Alabama  \n",
       "1  Table 3 - Alabama  \n",
       "2  Table 3 - Alabama  \n",
       "3  Table 3 - Alabama  \n",
       "4  Table 3 - Alabama  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssi2007.head()#check a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of dataframes and a list of years\n",
    "ssi_files = [df_ssi2016,df_ssi2015,df_ssi2014,df_ssi2013,\n",
    "         df_ssi2012,df_ssi2011,df_ssi2010, df_ssi2009,df_ssi2008, df_ssi2007]\n",
    "\n",
    "years = ['2016', '2015', '2014', '2013', '2012', '2011', '2010', '2009', '2008','2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to edit state name\n",
    "def state_name(var):\n",
    "    x = var.split('-').pop()#split the string at the hyphen and return the last string\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that loops function above, puts state and county in lowercase letters, and adds year\n",
    "def location_year(df, year):\n",
    "    df['state'] = df['state'].apply(lambda x: state_name(x))\n",
    "    df['state'] = df['state'].apply(lambda x: str(x).lower())\n",
    "    df['county'] = df['county'].apply(lambda x: str(x).lower())\n",
    "    df['year'] = year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the list of dataframes, running abive function and storing data in dict\n",
    "ssi = {}\n",
    "for i in range(len(ssi_files)):\n",
    "    ssi[i] = location_year(ssi_files[i], years[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one large dataframe \n",
    "ssi_data = [ssi[0], ssi[1], ssi[2], ssi[3], ssi[4], ssi[5], ssi[6], ssi[7], ssi[8], ssi[9]]\n",
    "ssi_df = pd.concat(ssi_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31417, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssi_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to a csv file\n",
    "#ssi_df.to_csv('ssi_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Data by County "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiled Bureau of Labor Stats data found on Kaggle: \n",
    "https://www.kaggle.com/jayrav13/unemployment-by-county-us/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_df = pd.read_csv('ALL_unemployment_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Newton County</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Panola County</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Monroe County</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Hinds County</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>February</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Kemper County</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year     Month        State         County  Rate\n",
       "0  2015  February  Mississippi  Newton County   6.1\n",
       "1  2015  February  Mississippi  Panola County   9.4\n",
       "2  2015  February  Mississippi  Monroe County   7.9\n",
       "3  2015  February  Mississippi   Hinds County   6.1\n",
       "4  2015  February  Mississippi  Kemper County  10.6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format the dataframe by renaming columns and making strings lowercase\n",
    "un_df.columns = map(str.lower, un_df.columns)\n",
    "un_df.rename({'rate': 'unemploy_rate'}, axis=1, inplace=True)\n",
    "un_df.county = un_df.county.apply(lambda x: x.lower())\n",
    "un_df.state = un_df.state.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split the county name and remove the last word \"county\"\n",
    "def split(value):\n",
    "    value = value.split(\" \")[:-1]\n",
    "    return ' '.join(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all counties in column\n",
    "un_df.county = un_df.county.apply(lambda x: split(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate dataframes of years needed\n",
    "un_16 = un_df[un_df.year == 2016]\n",
    "un_15 = un_df[un_df.year == 2015]\n",
    "un_14 = un_df[un_df.year == 2014]\n",
    "un_13 = un_df[un_df.year == 2013]\n",
    "un_12 = un_df[un_df.year == 2012]\n",
    "un_11 = un_df[un_df.year == 2011]\n",
    "un_10 = un_df[un_df.year == 2010]\n",
    "un_09 = un_df[un_df.year == 2009]\n",
    "un_08 = un_df[un_df.year == 2008]\n",
    "un_07 = un_df[un_df.year == 2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of dataframes to loop through\n",
    "unemploy = [un_16, un_15, un_14, un_13, un_12, un_11, un_10, un_09, un_08, un_07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not need monthly data, take the average of all monthly to get annual data\n",
    "un_16 = un_16.groupby(['state','county']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all years to get average annual unemployment rate by grouping together county and state and taking the mean\n",
    "for i in range(len(unemploy)): \n",
    "    unemploy[i] = unemploy[i].groupby(['state','county']).mean()\n",
    "    unemploy[i].reset_index(inplace=True)\n",
    "    unemploy[i].unemploy_rate = unemploy[i].unemploy_rate.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>year</th>\n",
       "      <th>unemploy_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>autauga</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama</td>\n",
       "      <td>barbour</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabama</td>\n",
       "      <td>bibb</td>\n",
       "      <td>2016</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alabama</td>\n",
       "      <td>blount</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state   county  year  unemploy_rate\n",
       "0  alabama  autauga  2016           5.21\n",
       "1  alabama  baldwin  2016           5.35\n",
       "2  alabama  barbour  2016           8.53\n",
       "3  alabama     bibb  2016           6.51\n",
       "4  alabama   blount  2016           5.43"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine all dataframes into one large dataframe\n",
    "emp_df = pd.concat(unemploy, axis=0)\n",
    "emp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to a csv file\n",
    "#emp_df.to_csv('unemployment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
